{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292c95df",
   "metadata": {},
   "source": [
    "# 파이토치 실습\n",
    "\n",
    "tensor는 넘파이 어레이와 유사하며 추가로 gpu를 사용해서 연산가속도 가능하다.? (gpu,cpu차이 강의 영상 다시 보기...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cc46face",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c57470d",
   "metadata": {},
   "source": [
    "### 1. 초기화 되지 않은(더미값) 5 X 3 행렬을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a51b54f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1313,  1.9125, -0.6901],\n",
      "        [ 0.1264,  1.4997, -0.3171],\n",
      "        [-0.5893,  0.5634,  1.6192],\n",
      "        [ 0.0734,  2.1759,  0.1287],\n",
      "        [-0.0481,  0.5343,  0.2385]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c6185b",
   "metadata": {},
   "source": [
    "### 2. 무작위로 초기화된 행렬을 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e7ba08",
   "metadata": {},
   "source": [
    "## randn\n",
    "원소들을 표준정규분표에서 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37816035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9936,  1.1287, -1.6031],\n",
      "        [-0.2726,  0.3924,  0.1579],\n",
      "        [ 0.1331,  0.0446, -0.5047],\n",
      "        [ 0.8555, -0.5236,  0.0088],\n",
      "        [ 2.3798,  1.6349,  0.3311]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39aeaa",
   "metadata": {},
   "source": [
    "## rand\n",
    "0~1 사이 값을 샘플링해서.(음수값이 없음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cc2a0e",
   "metadata": {},
   "source": [
    "### 3. dtype이 long이고 0으로 채워진 행렬을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0bc47e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5,3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6fd6c3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5,3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f6b6d",
   "metadata": {},
   "source": [
    "### 4. 데이터로부터 tensor 직접 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b5f8da5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5 ,3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2e77cd",
   "metadata": {},
   "source": [
    "### 5. 또는 존재하는 tensor를 바탕으로 tensor를 만든다. 이 method는 사용자로부터 제공된 새로운 값이 없는 한,  \n",
    "### 입력 텐서의 속성들을 재사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "85d1a2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5,3,dtype = torch.double)\n",
    "print(x)\n",
    "\n",
    "# 떠블형태가 뭐임??...\n",
    "# x가 떠블이라는 뜻이 모르겠따."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "231bf0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0300,  1.7290, -0.5493],\n",
      "        [-1.2793,  1.5763, -0.2139],\n",
      "        [-1.0108,  0.0847, -1.8758],\n",
      "        [-0.9687, -0.3461, -1.0123],\n",
      "        [ 1.5064,  0.7075, -0.0358]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype = torch.float) # 앞의 x 크기(5x3만큼 생성)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76500397",
   "metadata": {},
   "source": [
    "## 6. 행렬의 크기를 구하기 = 자주 활용하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29b4815a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b4e5d",
   "metadata": {},
   "source": [
    "### 덧셈 : 문법1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "afd32e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0300,  1.7290, -0.5493],\n",
      "        [-1.2793,  1.5763, -0.2139],\n",
      "        [-1.0108,  0.0847, -1.8758],\n",
      "        [-0.9687, -0.3461, -1.0123],\n",
      "        [ 1.5064,  0.7075, -0.0358]])\n",
      "tensor([[0.6050, 0.5390, 0.5969],\n",
      "        [0.5551, 0.2683, 0.6083],\n",
      "        [0.7643, 0.3443, 0.5674],\n",
      "        [0.8503, 0.5130, 0.2116],\n",
      "        [0.6362, 0.3494, 0.8416]])\n",
      "tensor([[ 0.5751,  2.2681,  0.0476],\n",
      "        [-0.7242,  1.8446,  0.3944],\n",
      "        [-0.2465,  0.4291, -1.3083],\n",
      "        [-0.1184,  0.1669, -0.8007],\n",
      "        [ 2.1426,  1.0568,  0.8058]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5,3)\n",
    "print(x)\n",
    "print(y)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581357a9",
   "metadata": {},
   "source": [
    "### 덧셈 : 문법2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "831dff1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5751,  2.2681,  0.0476],\n",
      "        [-0.7242,  1.8446,  0.3944],\n",
      "        [-0.2465,  0.4291, -1.3083],\n",
      "        [-0.1184,  0.1669, -0.8007],\n",
      "        [ 2.1426,  1.0568,  0.8058]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x,y))\n",
    "\n",
    "#1,2 번이 똑같은 결과가 출력되는 것을 할 수 있다.!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c6ffdc",
   "metadata": {},
   "source": [
    "### 덧셈 : 결과 tensor를 인자로 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64069c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5751, 2.2681, 0.0476],\n",
      "        [0.7242, 1.8446, 0.3944],\n",
      "        [0.2465, 0.4291, 1.3083],\n",
      "        [0.1184, 0.1669, 0.8007],\n",
      "        [2.1426, 1.0568, 0.8058]])\n",
      "tensor([[ 0.5751,  2.2681,  0.0476],\n",
      "        [-0.7242,  1.8446,  0.3944],\n",
      "        [-0.2465,  0.4291, -1.3083],\n",
      "        [-0.1184,  0.1669, -0.8007],\n",
      "        [ 2.1426,  1.0568,  0.8058]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5,3)\n",
    "print(result)\n",
    "\n",
    "torch.add(x,y, out = result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23a6912",
   "metadata": {},
   "source": [
    "### 덧셈 : 바꿔치기(inplce)방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "54ba05ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6050, 0.5390, 0.5969],\n",
      "        [0.5551, 0.2683, 0.6083],\n",
      "        [0.7643, 0.3443, 0.5674],\n",
      "        [0.8503, 0.5130, 0.2116],\n",
      "        [0.6362, 0.3494, 0.8416]])\n",
      "tensor([[ 0.5751,  2.2681,  0.0476],\n",
      "        [-0.7242,  1.8446,  0.3944],\n",
      "        [-0.2465,  0.4291, -1.3083],\n",
      "        [-0.1184,  0.1669, -0.8007],\n",
      "        [ 2.1426,  1.0568,  0.8058]])\n"
     ]
    }
   ],
   "source": [
    "# adds x to y\n",
    "print(y)\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b4f6a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바꿔치기 방식으로 텐서값을 변경하느 연산은 _접미사를 갖는다.\n",
    "# 예시 : x,copy_(y),x.t_()는 x를 변경하는 것이다.\n",
    "# 그러나 다음과 같이 넘파이같은 인덱싱 표기방법을 사용할 수도 있다고 함!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cca8cdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0300,  1.7290, -0.5493],\n",
      "        [-1.2793,  1.5763, -0.2139],\n",
      "        [-1.0108,  0.0847, -1.8758],\n",
      "        [-0.9687, -0.3461, -1.0123],\n",
      "        [ 1.5064,  0.7075, -0.0358]])\n",
      "tensor([ 1.7290,  1.5763,  0.0847, -0.3461,  0.7075])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8056b6",
   "metadata": {},
   "source": [
    "# 크기(차원) 변경 : 텐서의 크기나 모양을 변경하고 싶다면 torch.view릉 사용한다. 굉장히 많이 쓰이고 유용한 함수다!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "21e0c121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7727, -0.2042,  0.5101, -0.4648],\n",
      "        [-0.4912,  0.4123, -0.7462,  0.6838],\n",
      "        [-0.7494, -0.1421, -0.4728,  0.3938],\n",
      "        [ 0.1124, -0.4285,  1.2008, -0.1009]])\n",
      "tensor([ 0.7727, -0.2042,  0.5101, -0.4648, -0.4912,  0.4123, -0.7462,  0.6838,\n",
      "        -0.7494, -0.1421, -0.4728,  0.3938,  0.1124, -0.4285,  1.2008, -0.1009])\n",
      "tensor([[ 0.7727, -0.2042],\n",
      "        [ 0.5101, -0.4648],\n",
      "        [-0.4912,  0.4123],\n",
      "        [-0.7462,  0.6838],\n",
      "        [-0.7494, -0.1421],\n",
      "        [-0.4728,  0.3938],\n",
      "        [ 0.1124, -0.4285],\n",
      "        [ 1.2008, -0.1009]])\n",
      "torch.Size([16]) torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,4)\n",
    "print(x)\n",
    "\n",
    "y = x.view(16) # 16개의 차원을 가진 벡터로 죽 늘리겠다~~\n",
    "z = y.view(-1,2) # y 같이 퍼져있는 벡터 형태 텐서를,...-1은 자동으로, 남는 원소를 넣어줘라, 2는 두 개씩?\n",
    "print(y)\n",
    "print(z) # (8,2) 형태\n",
    "print(y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c62d840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만약 tensor에 하나의 값만 존재한다면, item()을 사용하면 숫자 값을 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a4551d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2837])\n",
      "<class 'torch.Tensor'> <class 'float'>\n",
      "-0.2837134301662445\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "\n",
    "print(type(x), type(x.item()))\n",
    "print(x.item())\n",
    "\n",
    "#tensor 값을 float형태로 추출하는 함수이다/11!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db85c06",
   "metadata": {},
   "source": [
    "# 참고.. : 전치,인덱싱,슬라이싱,수학계산,선형대수,난수 등과 같은 100가지 이상 텐서 연산은 토치 홈페이지에서 참고해보자..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa41b8e9",
   "metadata": {},
   "source": [
    "# Numpy변환(Bridge)\n",
    "\n",
    "torch tensor를 넘파이배열(array)로 변환하거나., 그 반대로 하는 것은 정말 쉽다.\n",
    "cpu상 토치텐서와 넘파이 배열은 저장 공간을 공유하기 떄문이다, 하나를 변경하면 다른 ㄹ하나도 변경."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8d2f8fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c35560e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "91a4ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넘피 배열의 값이 어떻게 변할까??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "750d031f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dc8ddb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 4., 4., 4., 4.])\n",
      "[3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "temp = a.clone()\n",
    "temp_numpy = temp.numpy()\n",
    "\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(temp_numpy)\n",
    "\n",
    "# 독립으로 사용하는 경우는 별로 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265626a9",
   "metadata": {},
   "source": [
    "### 넘파이 배열을 토치 텐서로 변환하기(넘파이를 변경하면 토치텐서 값도 자동변경된다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7d9aa0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "print(a)\n",
    "b= torch.from_numpy(a)\n",
    "np.add(a,1,out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b889fd5",
   "metadata": {},
   "source": [
    "## CUDA Tensors(쿠다 환경 설정이 꽤 복잡해보이므로 일단 패쓰!!하자..)\n",
    ".to 메소드를 사용해서 tensor를 어떠한 장치로도 옮길 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ff02789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#이 쿠다가 사용가능한 환경에서만 실행하낟. torch device를 사용하여 tensor를 gpu안팎으로 이동해보자\n",
    "\n",
    "x = torch.rand(4,4)\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\" # torch.device(\"cuda:0\")           # CUDA장치 객체 (device object)로...\n",
    "    y = torch.ones_like(X, device = device) #GPU 상에 직접적으로 tensor를 생성하거나???\n",
    "    print(y)\n",
    "    \n",
    "    \n",
    "    x = x.to(device)   \n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c99eae5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r8/hnw1hjlx54z7_g14njp906m00000gp/T/ipykernel_56656/3413304046.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "x = x.cuda()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
