{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_CNN_TensorFlow_(VGGNet_training)",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. TensorFlow 및 기타 라이브러리 가져 오기"
      ],
      "metadata": {
        "id": "bYVUgULpHJB1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx5B00cnG5dQ",
        "outputId": "1ab4a23e-e9b1-469b-b278-f5c904214ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "tensorflow version 2.8.2\n"
          ]
        }
      ],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "keras = tf.keras\n",
        "\n",
        "print(\"tensorflow version\",tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224 # 모든 이미지는 224x224으로 크기 조정g해버리기\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE=128\n",
        "learning_rate = 0.0001"
      ],
      "metadata": {
        "id": "QkgeVhFVG8fS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 데이터 세트 다운로드 및 탐색\n"
      ],
      "metadata": {
        "id": "9CpJ7ZMSHIEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "#분류할 클래스 개수 \n",
        "num_classes=10 # Cifar10의 클래스 개수\n",
        "\n",
        "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
        "    'cifar10',\n",
        "    split=['train[:90%]', 'train[90%:]', 'test'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")\n",
        "\n",
        "print(\"Train data 개수:\",len(raw_train))\n",
        "print(\"Val data 개수:\",len(raw_validation))\n",
        "print(\"Test data 개수:\",len(raw_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc9VERhGHMFl",
        "outputId": "fda3c712-17c3-4e54-bdf9-ba5cd5155a06"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset 162.17 MiB (download: 162.17 MiB, generated: 132.40 MiB, total: 294.58 MiB) to ~/tensorflow_datasets/cifar10/3.0.2...\u001b[0m\n",
            "\u001b[1mDataset cifar10 downloaded and prepared to ~/tensorflow_datasets/cifar10/3.0.2. Subsequent calls will reuse this data.\u001b[0m\n",
            "Train data 개수: 45000\n",
            "Val data 개수: 5000\n",
            "Test data 개수: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 데이터 정규화(tf.image 모듈을 사용하여 이미지를 정규화)"
      ],
      "metadata": {
        "id": "tv1JDaUzHh6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_example(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = (image/127.5) - 1\n",
        "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "QyDfcIZRHmkC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #map 함수를 사용하여 데이터셋의 각 항목에 데이터 포맷 함수를 적용함\n",
        "train = raw_train.map(format_example)\n",
        "validation = raw_validation.map(format_example)\n",
        "test = raw_test.map(format_example)"
      ],
      "metadata": {
        "id": "QG-QGV3zHnxO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 데이터 세트 만들기"
      ],
      "metadata": {
        "id": "fj-S6FnyHyrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SHUFFLE_BUFFER_SIZE = 1000\n",
        "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "validation_batches = validation.batch(BATCH_SIZE)\n",
        "test_batches = test.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "q9q9urB7H1Xu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 데이터 검사하기"
      ],
      "metadata": {
        "id": "3-46nP8zH5Lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 가시화해버리기\n",
        "get_label_name = metadata.features['label'].int2str\n",
        "\n",
        "for image, label in raw_train.take(2):\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.title(get_label_name(label))"
      ],
      "metadata": {
        "id": "HrliAxr3H7lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 사용할 CNN 모델 불러오기"
      ],
      "metadata": {
        "id": "UKe0z-ZvICR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "#CNN 모델 변경하려면 여기서 변경.\n",
        "#ImageNet으로 사전 훈련된 모델 호출\n",
        "base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
        "                                               include_top=True,\n",
        "                                                classes=1000,\n",
        "                                               weights='imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2aqTI-jH_fC",
        "outputId": "b92fc949-936f-4971-df0e-7c80517f3d79"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 3s 0us/step\n",
            "553476096/553467096 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6-1 불러온 모델에서 데이터 셋의 클래스 수에 맞게 최종 분류층 교체"
      ],
      "metadata": {
        "id": "oxyerIzuILH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "for layer in base_model.layers[:-1]: \n",
        "    model.add(layer)\n",
        "#마지막 layer의 최종 분류 개수를 클래스 개수와 맞게 설정해ㅎ야함\n",
        "model.add(keras.layers.Dense(num_classes, activation='softmax',name='predictions'))"
      ],
      "metadata": {
        "id": "807JGl5hIMUY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6-2 모델 아키텍처 살펴보기\n",
        "\n"
      ],
      "metadata": {
        "id": "I-Mzf3tTIZP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nD-irADIbOp",
        "outputId": "cc5ef4f4-1f8c-4214-a6fa-47584194d6f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 10)                40970     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,301,514\n",
            "Trainable params: 134,301,514\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. 모델 컴파일"
      ],
      "metadata": {
        "id": "PJp85aJTIp_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNsCX5baIpb-",
        "outputId": "3cd8c5cb-fd62-45b6-c799-bbd63fcf4290"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. 모델 훈련"
      ],
      "metadata": {
        "id": "9kck-VHiIn04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_batches,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=validation_batches,\n",
        "                    batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et2HyUn7I8zX",
        "outputId": "6ac8145d-d8b1-401c-c66c-e109e6884ba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. 학습 곡선 그리기\n",
        "\n"
      ],
      "metadata": {
        "id": "-1PkHWEAJGNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d882eL0eJJV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라스트! Test Set으로 학습된 모델 테스트하기"
      ],
      "metadata": {
        "id": "agHMapQkJL2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_and_metrics = model.evaluate(test_batches, batch_size=64)\n",
        "print(\"테스트 성능 : {}%\".format(round(loss_and_metrics[1]*100,4)))"
      ],
      "metadata": {
        "id": "W-_F_c0XJRYA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}