"""
일어날 가능성있는 outcome들의 집합(예: {1, 2, 3, 4, 5, 6})
Sample Space의 부분집합(예: 주사위를 던져 홀수가 나오는 experient, {1,3,5})
퀴즈 : 주사위를 2번 던져 앞면이 나올 이벤트를 구하라
정답 : P(H,H), (H,T), (T, H)}

P(α)=limn−>∞N(α)n
정의를 해석하자면 n을 무수히 많이 시도하면 결국 확률은 수렴한다는 것이다. 예를 들어 주사위에서 특정 숫자가 나올 확률은 16이 된다.

1. 확률의 성질

0≤P(A)≤1
P(S)=1
A1 ~ An이 서로 독립확률이면 아래 수식을 만족한다.

P(A1∪…∪An)=∑i=1nP(Ai)
P(A∩C)=P(A,C)

2. 사전 확률(Prior)
충치가 있을 확률 0.1, 충치가 없을 확률 0.9
P(Cavity)=0.1

3. 사후 확률(Posterior)

아래의 뜻은 치통이 있는 사람 중에 80%는 충치일 가능성이 있다는 것이다.
P(Cavity/Tootache)=0.8

조건부 확률의 수학적 정의는 아래와 같다.

P(A|B)=P(A,B)P(B)

이 또한 유사하게 아래와 같이 나타낸다.

P(B|A)=P(A,B)P(A)

또한 이를 수식 이동을 통해 아래와 같이 나타낼 수 있다.
연쇄법칙(Chain Rule)이 적용되는 것을 알 수 있다.

P(A,B)=P(A|B)P(B)=P(B|A)P(A)

3. 전체 확률의 법칙(Law of Total Probability)


A1,A2,…,An이 서로 독립적인 event이고 B는 어떤 이벤트라고 가정한다면 아래와 같은 법칙을 가지게 된다.

의미는 A와 B가 (집합의 개념에서)겹쳐지는 만큼의 조건부확률은 개별 조건부 확률의 합이라는 것이다.

P(B)=P(B,A1)+P(B,A2)+…+P(B,An)
이 수식은 P(A,B)=P(B|A)P(A)에 의해 아래와 같이 바꿔 나타낼 수 있다.

P(B|A1)P(A1)+P(B|A2)P(A2)+…+P(B|An)P(An)
이 수식을 간단하게 나타내면 아래와 같다.

∑nj=1P(B|Aj)P(Aj)


4. 베이즈 정리(Bayes Rule) 엄청 중요한 개념이다!!!!!!!자격증에서도 도움되니 반드시 이해와 정리가 필요하다.

머신 러닝 관련해서 가장 유명한 수식중 하나를 꼽자면 베이즈 정리가 아닐까 한다.

P(A|B)=P(B|A)P(A)P(B)
예를 들자면 환자들의 질병과 증상에 대해 얘기해보자. 질병과 증상 확률이 각각 확률일 가질때 주어진 증상에서 특정질병일 확률은 아래와 같이 표현 될 수 있다.

P(Disease|Symptom)=P(Symptom|Disease)P(Disease)P(Symptom)
이 수식을 이해하는 것이 중요한데 좀더 와닿게 “스팸 필터링” 머신러닝 문제로 이 확률이 어떻게 활용되는지 이해해보자.
스팸메일에서 coupon이란 단어가 들어있을때 스팸메일 확률은 오른쪽의 수식으로 부터 구해질 수 있다.
이때 오른쪽의 수식은 스팸메일 중에 쿠폰이란 단어가 등장할 확률, 전체메일에서 스팸메일일 확률, 스팸 메일에서 쿠폰이란 단어가 등장할 확률로 부터 구해질 수 있다.
재밌게도 이를 이용해 왼쪽의 쿠폰이란 단어가 메일에 포함될 때 스펨메일을 확률을 구할 수 있다.

P(spam|coupon)=P(coupon|spam)P(spam)P(coupon)
이를 단어 하나가 아니라 메일에서 등장하는 전체단어로 확장하게 되면 Naive Bayes를 이용한 스팸필터 모델이 된다.

스팸메일일 확률 = P(spam|coupon)P(spam|sex)…P(spam|casino)

또하나 예를 들자면 아래와 같은 문제를 생각해보자.

[퀴즈]
뇌수막염을 가진사람의 50%는 목이 뻣뻣하다.
뇌수막염 확률 P(M) 은 5만분의 1이다.
목이 뻣뻣할 확률 P(S) 20분의 1이다.
목이 뻣뻣한 환자가 병원에 오면 이사람의 뇌수막염일 확률은?

그럼 이를 베이즈 정리를 통해 수식화 하면 아래와 같다.

P(M|S)=P(S|M)P(M)P(S)
P(S|M)=0.5
P(M)=150000
P(S)=120
이를통해 계산하면 P(M|S)=0.0002이다.

4. 확률 독립(Independence)
만약 A와 B 사건이 서로 독립이면 아래의 수식을 만족한다.
P(A,B)=P(A)P(B)
뜻은 아래의 조건부 확률 수식에서 서로 독립이면 P(A|B)가 P(A)와 같기 때문이다.

P(A,B)=P(A|B)P(B)
A, B가 C에대해 조건부 독립이면 아래 수식을 만족한다.

P(A|B,C)=P(A|C)

5. 확률변수(Random Variable)
많은 실험에서 원본 확률 구조 보다 요약된 변수가 다루기 쉽다. 이를 위해 Random Variable을 사용한다.

예를 들어 50명이 찬성/반대 설문조사를 했다고 가정해보자.
* 이때 찬성을 1, 반대를 0으로 기록한다.
* 실험에 따른 sample space는 경우의 수에 의해 element수는 250이 된다.

element가 너무 많으니 우리는 사실 찬성에 대해서만 관심이 있다고 가정해보자.
* 다시 Random Variable X를 50명중에 1이 기록된 수라고 정의해보자.
* 그러면 0명~50명의 찬성이 있을수 있으니 sample space는 51개의 element를 가진다.



Random Variable은 프로그래밍의 하나의 함수 처럼 Random Experiment의 outcome을 특정 값으로 할당하는 것이다.

예를 들어 Random Variable을 아래와 같이 정의했다고 해보자.

Random Variable = 주사위를 2번 던져 나오는 수의 합

그러면 주사위를 2번 던져 (1,1)이 나왔다면 2로 맵핑된다.

주사위를 예제로 사용한 김에 이를 수식화 하면 아래와 같다.

S=<s1,s2,…,sn>
X=<x1,x2,…,xn>
X=Xj를 Random Variable이 관측될때를 뜻한다.
sj∈S일때 X(sj)=xj의 의미는 sample space에서 주사위의 합이 xj라는 뜻이다.
이를 수식화해보자.

P(X=xj)=∑sj:X(sj)=xjP(Sj)
쫄것 없다. 복잡해 보여도 하나하나 보면 이해가 간다.(오히려 SQL 쿼리라고 생각하고 이해해보자.) 예제를 들어보자. 주사위를 2번던져 합이 5가 나올 확률을 위의 수식으로 설명해보자. P(X=xj)의 의미는 random variable이 xj일 확률이란 뜻이다. 이때 ∑sj:X(sj)=xjP(Sj)의 뜻은 sample space는 (1,4), (2,3), (3,2), (4,1)가 나올 확률을 다 더한것이 Random Variable 5가 나올 확률이란 뜻이다.

위 예제를 계산해보면 아래와 같다.

P(X=5)=P((1,4))+P((2,3))+P((3,2))+P((4,1))=4/36=1/9

6. 이산/연속 확률 변수(Discrete/Continuous Random Variable)

이산 확률변수는 이산값을 가정한다.
연속 확률 변수는 연속 확률값을 가전한다.
Probability mass/density function은 pmf/pdf라고 불린다.
대문자 PDF는 Probability Distiribution Function이다.

7. pmf(probability mass function)
pmf는 이산값의 확률 변수를 표시하기 위한 수단이다.



각 x의 확률값의 합은 1이기 때문에 아래의 수식으로 나타낼 수 있다.

∑xp(x)=1

a보다 크고 b보다 작은 X의 확률은 아래와 같이 a에서 b사이의 확률의 합으로 나타낼 수 있다.

P(a<X<b)=∑k=abp(k)


8. pdf(probability density function)

pdf는 연속된 확률 변수를 표시하기 위한 수단이다.



이산값과 달리 연속값이므로 -무한대 ~ 무한대까지 p(x)를 적분하면 전체확률 1이 나온다.

∫∞−∞p(x)dx=1
또한 a ~ b사이의 확률은 아래와 a ~ b 사이의 적분으로 나타낼 수 있다.

P(a<X<b)=∫bap(t)dt

9. PDF(Probability Distiribution Fuction)
대문자 PDF는 확률이 p(x)이하일때까지의 누적 확률이다.

F(x)=P(X≤x)
PDF는 2개의 성질을 지닌다.

0≤F(x)≤1
F(x) 는 연속된 함수이다.
만약 이산값을 가지면 PDF는 아래와 같이 나타낼 수 있다.
쉽게 얘기하자면 이산값이면 간단히 sum하고 연속값이면 적분한다.

x가 이산값이면 아래와 같은 수식이 성립한다.
F(x)=P(X≤x)=∑k=0xP(X=k)=∑k=0xp(k)
이산값일때의 PDF 계산 예제는 아래와 같다.

X가 연속값이면 아래와 같이 x까지 적분한다.

F(x)=∫x−∞p(t)dt for all x
p(x)의 정의는 당연히 F(x)를 미분한 함수이다.
또한 이 의미는 PDF 함수의 미분을 통해 pdf함수를 얻을수 있음을 의미한다.
어차피 pdf를 적분하여 얻는게 PDF 함수이니 당연한 말이긴 하다.

p(x)=dFdx(x)


10. 결합 확률 분포(Joint pmf),이산값일때만!!

 확률변수 n에 대해 아래의 수식이 만족한다.

∑x1,x2,…,xnp(x1,x2,…,xn)=1

여기서 결합 확률 분포라 함은 2개 이상의 확률 변수에 대해 수식 계산을 하는 방법이다.
(사실 위 수식은 n이 1이어도 결함이 없지만 joint 개념은 2개 이상 사용하긴 한다.)

헷갈리니 확률 변수가 x1, x2, …, xn이 아니라 충치여부는 X이고 치통은 Y라고 가정해보자. 충치일때는 x1, 충치가 아닐때는 x2, 치통이면 y1, 치통이 아니면 y2라고 정해보자. 여기서 위의 수식의 의미는 전체 확률(즉, 1)은 아래의 수식으로 구할수 있다는 뜻이다.

p(x1,y1)+p(x2,y1)+p(x1,y2)+p(x2,y2)=0.04+0.01+0.06+0.89=1


11. 결합 확률 분포(Joint pmf), 연속값일때

연속 확률변수일때는 p(x1,x2,…,xn)≥0 일때 joint pdf는 아래와 같다.
즉 위의 원리에서 연속값이니 적분을 이용하는 것만이 차이점이다.

∫x1…∫xnp(x1,x2,…,xn)dx1…dxn=1

12. 조건부 pdf(coditional pdf)
조건부 pdf는 아래의 조건부 확률 수식을 이용하여 아래와 같이 유도할 수 있다.

p(y|x)=p(x,y)p(x)
p(x,y)=p(y|x)p(x)
p(x1,x2,…,xn)=p(x1|x2,…,xn)p(x2|x3,…,xn)…p(xn−1|xn)p(xn)
조금더 쉽게 이해하자면 p(x,y)=p(y|x)p(x) 이 수식을 이용하기 위해 x1을 우선 y, 나머지를 x로 치환했다고 생각해보자.

치환을 이용해 전개하면 아래와 같이 된다.

p(y|x)p(x)=p(x1|x2,…,xn)p(x2,x3,…,xn)
다시 같은 방법으로 p(x_2,x_3,…,x_n) 에서 x2를 y, 나머지를 x라 치환해보자.

p(y|x)p(x)=p(x1|x2,…,xn)p(x2|x3,…,xn)p(x3,…,xn)
이를 연쇄법친으로 끝까지 가면 더이상 for-loop 돌듯이 마지막 변수 2개가 남을때 까지 갈 것이고 그건 p(xn−1,xn) 까지 일것이다. 그럼 이를 이용하면 최종적으로 아래와 같이 된다.

p(y|x)p(x)=p(x1|x2,…,xn)p(x2|x3,…,xn)…p(xn−1,xn)

13. 독립
확률 변수간 독립일 경우 수식이 간단해진다.

p(x,y)=p(x)p(y)
왜냐하면 p(x|y)가 p(x)랑 같기 때문이다.

14. 전체 확률의 법칙(Law of Total Probability)

전체 확률은 조건부 확률의 합으로 표현할 수 있다.

p(y)=∑xp(y|x)p(x)

15. Marginalization

주어진 joint pmf/pdf에서 Marginalization을 이용하여 확률변수의 어떤 부분 집합도 계산할 수 있다.
아래 수식을 보면 확률 p(x)는 p(x,y)의 모든 확률값을 더하면 p(x)가 나온다는 것이다.

p(x)=∫∞−∞p(x,y)dy
추상적이니 구체적으로 얘기하자면 바로 밑의 예제 풀어보기의 그림을 참고하여 설명을 하겠다.
아래와 같이 수식을 세우면 이해가 좀 더 편하다.

p(xx=x1)=∫∞−∞p(xx=x1,y)dy

위 수식은 x가 x1 일때의 확률은 p(xx=x1,y)의 확률의 합이랑 같다는 것이다.
즉 이는 다시 풀이하면 p(xx=x1)=p(xx=x1,yy=y1)+p(xx=x1,yy=y2)로 나타낼 수 있다.

다시 돌아와 p(x)=∫∞−∞p(x,y)dy는 아래와 같이 된다.

p(x)=p(xx=x1,yy=y1)+p(xx=x1,yy=y2)+p(xx=x2,yy=y1)+p(xx=x2,yy=y2)+p(xx=x3,yy=y1)+p(xx=x3,yy=y2)

이를 검증하면 아래와 같이 된다.

1.0=0.2+0.1+0.1+0.2+0.1+0.3
수식에서 y자리에 x2,…,xn을 치환하면 아래와 같은 수식이 된다.

p(x1,x2,…,xi−1,xi+1,…,xn)=∫∞−∞p(x1,x2,…,xn)dx

p(x1,x2)=∫x3…∫xnp(x1,x2,…,xn)dx3…dxn

"""